{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "572f5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE_URL = 'https://www.b9.com.br'\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36'\n",
    "}\n",
    "\n",
    "def get_soup(url):\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    response.raise_for_status()\n",
    "    response.encoding = 'utf-8'#test\n",
    "    return BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "def extract_references(post_url):\n",
    "    soup = get_soup(post_url)\n",
    "    references_section = soup.find('p', text=lambda x: x and 'REFERÊNCIAS' in x)\n",
    "    if not references_section:\n",
    "        return []\n",
    "    \n",
    "    references = []\n",
    "    for sibling in references_section.find_next_siblings():\n",
    "        if sibling.get_text(strip=True) == '========':\n",
    "            break\n",
    "        references.append(sibling.get_text(strip=True))\n",
    "    \n",
    "    return references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0348a3a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Assessment, management, and prevention of childhood temper tantrumshttps://journals.lww.com/jaanp/abstract/2012/10000/assessment,_management,_and_prevention_of.2.aspx', 'Temper Tantrums in Young Children: 2. Tantrum Duration and Temporal Organizationhttps://journals.lww.com/jrnldbp/fulltext/2003/06000/temper_tantrums_in_young_children__2__tantrum.3.aspx?casa_token=XT0dxgcDQJMAAAAA:KXBH6vF25IZT4vBlzGF3SysfHTm6XlWlcOFuAp_pcIfqXl2s_-yU_6pvKirSKoFbV8Y7jLlaqqq8zdLWV0W4NmaXTw', 'Temper Tantrums in Young Children: 1. Behavioral Compositionhttps://journals.lww.com/jrnldbp/fulltext/2003/06000/temper_tantrums_in_young_children__1__behavioral.2.aspx?casa_token=86hhrSeXMh0AAAAA:ZEF3NP81tjsathb5NVrGbcc08KdVqBjLNRBGr4pwZAkkRZszvPoUyZuTzdnwyRjirZ_ejI11i9YDHUVa3uNK1EAEOg', 'Meltdown/Tantrum Detection System for Individuals with Autism Spectrum Disorderhttps://www.tandfonline.com/doi/full/10.1080/08839514.2021.1991115', 'Developmental pathways from preschool temper tantrums to later psychopathologyhttps://www.cambridge.org/core/journals/development-and-psychopathology/article/abs/developmental-pathways-from-preschool-temper-tantrums-to-later-psychopathology/6668E79FAD80D21A26E3A2E8FB10D322', 'Emotional Development in Early Infancyhttps://www.jstor.org/stable/1125359?origin=crossref', 'Screaming, Yelling, Whining and Crying: Categorical and intensity differences in Vocal Expressions of Anger and Sadness in Children’s Tantrumshttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC3192404/', 'Young Children’s Understanding of the Causes of Anger and Sadnesshttps://www.jstor.org/stable/1131944?origin=crossref', 'A systematic review of the effects of motor interventions to improve motor, cognitive, and/or social functioning in people with severe or profound intellectual disabilitieshttps://www.sciencedirect.com/science/article/pii/S0891422214002066?casa_token=gb8j_4rhocMAAAAA:IFAnWFT5NKwINV1Ty0eWBu55ZZS0eQ3zS5_Ud1INCjKDLyZqvV4KdP3rh00_NzwHfusKkdEANQ', 'Emotional self-regulation in preschoolers: The interplay of child approach reactivity, parenting, and control capacities.https://psycnet.apa.org/doiLanding?doi=10.1037%2F0012-1649.42.1.84', 'Cognitive systems for revenge and forgivenesshttps://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/cognitive-systems-for-revenge-and-forgiveness/3EE59DAB2918E5E72105B14FB589150E', 'The role of loudness in vocal intimidation.https://psycnet.apa.org/record/2024-28586-001', 'Understanding Phasic Irritability: Anger and Distress in Children’s Temper Outburstshttps://link.springer.com/article/10.1007/s10578-021-01126-5', 'A Cross-Sectional Study of Onset, Cessation, Frequency, and Duration of Children’s Temper Tantrums in a Nonclinical Samplehttps://journals.sagepub.com/doi/10.2466/pr0.106.2.448-454', 'Naruhodo#83 – O que são sonhos?https://www.youtube.com/watch?v=rKvDGxCg7XE', 'Naruhodo#156 – O que é paralisia do sono?https://www.youtube.com/watch?v=h9om8soj_uA', 'Naruhodo#123 – O que é e como funciona o sonho lúcido?https://www.youtube.com/watch?v=ThUlmkFFr1U', 'Naruhodo#164 – Podemos ler emoções com base em expressões faciais?https://www.youtube.com/watch?v=cq4oeBZ5kgo', 'Naruhodo#407 – Existe razão sem emoção?https://www.youtube.com/watch?v=qUxluRrHV3E', 'Naruhodo#348 – Sentir medo e ansiedade é algo ruim?https://www.youtube.com/watch?v=u30dN7ACvE4', 'Naruhodo#281 – Aprendemos mais quando somos punidos?https://www.youtube.com/watch?v=hy-SRTS9pW0']\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "post_url = 'https://www.b9.com.br/shows/naruhodo/naruhodo-418-o-que-e-a-birra/?highlight=naruhodo'\n",
    "references = extract_references(post_url)\n",
    "print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0be82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping post https://www.b9.com.br/shows/naruhodo/naruhodo-425-o-que-e-competitividade-parte-2-de-2/?highlight=naruhodo...\n",
      "Scraping post https://www.b9.com.br/shows/naruhodo/naruhodo-424-o-que-e-competitividade-parte-1-de-2/?highlight=naruhodo...\n",
      "Scraping post https://www.b9.com.br/shows/naruhodo/naruhodo-422-criancas-acreditam-em-contos-de-fadas/?highlight=naruhodo...\n",
      "Scraping post https://www.b9.com.br/shows/naruhodo/naruhodo-421-por-que-guardamos-segredos/?highlight=naruhodo...\n",
      "Scraping post https://www.b9.com.br/shows/naruhodo/naruhodo-420-maconha-faz-mal-parte-2-de-2/?highlight=naruhodo...\n",
      "Scraping post https://www.b9.com.br/shows/naruhodo/naruhodo-419-maconha-faz-mal-parte-1-de-2/?highlight=naruhodo...\n",
      "Data has been saved to references.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "\n",
    "SEARCH_URL = 'https://www.b9.com.br/?s=naruhodo&pagina={}'\n",
    "\n",
    "def get_podcast_posts(page_number):\n",
    "    soup = get_soup(SEARCH_URL.format(page_number))\n",
    "    return [a['href'] for a in soup.select('a.c-post-card__link')]\n",
    "\n",
    "def scrape_references():\n",
    "    all_references = []\n",
    "    for page in range(1,2):  # Loop through all pages\n",
    "        print(f'Scraping page {page}...')\n",
    "        post_links = get_podcast_posts(page)\n",
    "        for post_link in post_links:\n",
    "            print(f'Scraping post {post_link}...')\n",
    "            references = extract_references(post_link)\n",
    "            all_references.append([post_link] + references)\n",
    "            time.sleep(1)  # Be polite and don't overwhelm the server\n",
    "    return all_references\n",
    "\n",
    "def save_to_csv(data, filename='references.csv'):\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    references = scrape_references()\n",
    "    save_to_csv(references)\n",
    "    print(\"Data has been saved to references.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e30ef72",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 19 fields in line 4, saw 25\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Step 1: Read and Process the CSV File\u001b[39;00m\n\u001b[0;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreferences.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Adjust column names to set the first column as 'Episode'\u001b[39;00m\n\u001b[0;32m      8\u001b[0m data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReference_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpisode\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m     (\n\u001b[0;32m   1745\u001b[0m         index,\n\u001b[0;32m   1746\u001b[0m         columns,\n\u001b[0;32m   1747\u001b[0m         col_dict,\n\u001b[1;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:843\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:904\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:879\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2058\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 19 fields in line 4, saw 25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read and Process the CSV File\n",
    "file_path = 'references.csv'\n",
    "data = pd.read_csv(file_path, header=None, sep=',')\n",
    "\n",
    "# Adjust column names to set the first column as 'Episode'\n",
    "data.columns = [f'Reference_{i}' if i > 1 else 'Episode' for i in range(1, len(data.columns) + 1)]\n",
    "\n",
    "# Set the first column ('Episode') as the index\n",
    "data.set_index('Episode', inplace=True)\n",
    "\n",
    "# Transpose the DataFrame to make episodes as columns\n",
    "data_transposed = data.transpose()\n",
    "\n",
    "# Fill empty values with an empty string\n",
    "data_transposed.fillna(value='', inplace=True)\n",
    "\n",
    "# Export the processed DataFrame to a CSV file\n",
    "export_path = 'path_to_your_file/processed_references.csv'\n",
    "data_transposed.to_csv(export_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a96068e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_3152\\1349924244.py:41: DeprecationWarning: write_transaction has been renamed to execute_write\n",
      "  session.write_transaction(create_graph, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been imported into Neo4j\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import csv\n",
    "\n",
    "# Neo4j connection details\n",
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"senha123\"\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "def load_data(filename='references.csv'):\n",
    "    data = []\n",
    "    with open(filename, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "def create_graph(tx, data):\n",
    "    for row in data:\n",
    "        episode = row[0]\n",
    "        references = row[1:]\n",
    "        \n",
    "        # Create or merge the episode node\n",
    "        tx.run(\"MERGE (e:Episode {url: $episode})\", episode=episode)\n",
    "        \n",
    "        for ref in references:\n",
    "            # Create or merge the reference node\n",
    "            tx.run(\"MERGE (r:Reference {url: $ref})\", ref=ref)\n",
    "            # Create the relationship\n",
    "            tx.run(\"\"\"\n",
    "                MATCH (e:Episode {url: $episode})\n",
    "                MATCH (r:Reference {url: $ref})\n",
    "                MERGE (e)-[:REFERENCES]->(r)\n",
    "            \"\"\", episode=episode, ref=ref)\n",
    "\n",
    "def main():\n",
    "    data = load_data()\n",
    "    with driver.session() as session:\n",
    "        session.write_transaction(create_graph, data)\n",
    "    print(\"Data has been imported into Neo4j\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136a1522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
